{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.image as mpimg\n",
    "import tkinter as tk\n",
    "from matplotlib.figure import Figure\n",
    "from IPython.display import display, HTML\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.ticker as ticker\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow.keras as ks\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import backend as Ks\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCNNModeltoInterpret(fname):\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.0\n",
    "    model = ks.Sequential()\n",
    "    # Conv Layer 1\n",
    "    model.add(ks.layers.Conv1D(filters=10, kernel_size=5, strides=1, input_shape=(None,3),\n",
    "                           padding='same',use_bias=True, \n",
    "                           kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Conv Layer 2-11 (10 layers)\n",
    "    for layernum in range(10):\n",
    "        model.add(ks.layers.Conv1D(filters=10, kernel_size=5, strides=1,\n",
    "                           padding='same',use_bias=True, \n",
    "                           kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # Conv Layer 12\n",
    "    model.add(ks.layers.Conv1D(filters=1, kernel_size=5, strides=1,\n",
    "                           padding='same',use_bias=True, \n",
    "                           kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    previousModel = ks.models.load_model(fname)\n",
    "    model.set_weights(previousModel.get_weights())\n",
    "    return model\n",
    "\n",
    "def getCNNSegMap(model, dfstat, data):\n",
    "    TOTAL_LEN = np.shape(data)[0]\n",
    "\n",
    "    mRR = dfstat['Mean'][dfstat['Parameter']=='RR'].values[0]\n",
    "    sdRR = dfstat['StdDev'][dfstat['Parameter']=='RR'].values[0]\n",
    "    mSpO2 = dfstat['Mean'][dfstat['Parameter']=='SpO2'].values[0]\n",
    "    sdSpO2 = dfstat['StdDev'][dfstat['Parameter']=='SpO2'].values[0]\n",
    "    mHR = dfstat['Mean'][dfstat['Parameter']=='HR'].values[0]\n",
    "    sdHR = dfstat['StdDev'][dfstat['Parameter']=='HR'].values[0]\n",
    "\n",
    "    rrnaf = (data['RRraw'].values - mRR)/sdRR\n",
    "    spo2naf = (data['SpO2raw'].values - mSpO2)/sdSpO2\n",
    "    hrnaf = (data['HRraw'].values - mHR)/sdHR\n",
    "    \n",
    "    X_TEST = np.zeros((1,TOTAL_LEN,3), dtype=np.float32)\n",
    "    X_TEST[0,:,0] = rrnaf\n",
    "    X_TEST[0,:,1] = spo2naf\n",
    "    X_TEST[0,:,2] = hrnaf\n",
    "    predictions = model.predict(X_TEST)\n",
    "    return predictions[0,:,0]\n",
    "\n",
    "def getPosProbSAX(refProbDf, dfstat, data):\n",
    "    mRR = dfstat['Mean'][dfstat['Parameter']=='RR'].values[0]\n",
    "    sdRR = dfstat['StdDev'][dfstat['Parameter']=='RR'].values[0]\n",
    "    mSpO2 = dfstat['Mean'][dfstat['Parameter']=='SpO2'].values[0]\n",
    "    sdSpO2 = dfstat['StdDev'][dfstat['Parameter']=='SpO2'].values[0]\n",
    "    mHR = dfstat['Mean'][dfstat['Parameter']=='HR'].values[0]\n",
    "    sdHR = dfstat['StdDev'][dfstat['Parameter']=='HR'].values[0]\n",
    "    tdf = pd.DataFrame(columns=['RR','SpO2','HR','nRR','nSpO2','nHR','symRR','symSpO2','symHR','Symbol','Label'])\n",
    "    tdf['RR'] = data['RRraw'].values\n",
    "    tdf['SpO2'] = data['SpO2raw'].values\n",
    "    tdf['HR'] = data['HRraw'].values\n",
    "    tdf['nRR'] = (data['RRraw'].values - mRR)/sdRR\n",
    "    tdf['nSpO2'] = (data['SpO2raw'].values - mSpO2)/sdSpO2\n",
    "    tdf['nHR'] = (data['HRraw'].values - mHR)/sdHR\n",
    "    tdf['Label'] = data['Label'].values\n",
    "    cutpoints = [-np.inf,-1.5,-1,-0.5,0,0.5,1,1.5,np.inf]\n",
    "    tdf['symRR'] = pd.cut(tdf['nRR'], bins = cutpoints, labels=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "    tdf['symSpO2'] = pd.cut(tdf['nSpO2'], bins = cutpoints, labels=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "    tdf['symHR'] = pd.cut(tdf['nHR'], bins = cutpoints, labels=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "    tdf['Symbol'] = tdf.apply(lambda row: row['symRR']+ row['symSpO2']+row['symHR'],axis=1)\n",
    "    newtdf = pd.merge(tdf , refProbDf[['Symbol', 'PosProb']], how = 'left', left_on='Symbol', right_on='Symbol')\n",
    "    return newtdf['PosProb'].values\n",
    "\n",
    "def getSAXfromNormSeries(refProbDf,nRR,nSpO2,nHR):\n",
    "    tdf = pd.DataFrame(columns=['nRR','nSpO2','nHR','symRR','symSpO2','symHR','Symbol'])\n",
    "    tdf['nRR'] = nRR\n",
    "    tdf['nSpO2'] = nSpO2\n",
    "    tdf['nHR'] = nHR\n",
    "    cutpoints = [-np.inf,-1.5,-1,-0.5,0,0.5,1,1.5,np.inf]\n",
    "    tdf['symRR'] = pd.cut(tdf['nRR'], bins = cutpoints, labels=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "    tdf['symSpO2'] = pd.cut(tdf['nSpO2'], bins = cutpoints, labels=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "    tdf['symHR'] = pd.cut(tdf['nHR'], bins = cutpoints, labels=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "    tdf['Symbol'] = tdf.apply(lambda row: row['symRR']+ row['symSpO2']+row['symHR'],axis=1)\n",
    "    newtdf = pd.merge(tdf , refProbDf[['Symbol', 'PosProb']], how = 'left', left_on='Symbol', right_on='Symbol')\n",
    "    return newtdf['PosProb'].values\n",
    "\n",
    "def movingAvg(x,n):\n",
    "    y = np.zeros(len(x),dtype=np.float32)\n",
    "    ysum = 0\n",
    "    for i in range(len(x)):\n",
    "        if(i<n):\n",
    "            ysum += x[i]\n",
    "            y[i] = ysum/float(i+1)\n",
    "        else:\n",
    "            ysum = ysum + x[i] - x[i-n]\n",
    "            y[i] = ysum/float(n)\n",
    "    return y\n",
    "\n",
    "def getLSTMModeltoInterpret(fname):\n",
    "    previousModel = ks.models.load_model(fname)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(None, 3),return_sequences=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.set_weights(previousModel.get_weights())\n",
    "    return model\n",
    "\n",
    "def getLSTMSegMap(model, dfstat, data):\n",
    "    TOTAL_LEN = np.shape(data)[0]\n",
    "\n",
    "    mRR = dfstat['Mean'][dfstat['Parameter']=='RR'].values[0]\n",
    "    sdRR = dfstat['StdDev'][dfstat['Parameter']=='RR'].values[0]\n",
    "    mSpO2 = dfstat['Mean'][dfstat['Parameter']=='SpO2'].values[0]\n",
    "    sdSpO2 = dfstat['StdDev'][dfstat['Parameter']=='SpO2'].values[0]\n",
    "    mHR = dfstat['Mean'][dfstat['Parameter']=='HR'].values[0]\n",
    "    sdHR = dfstat['StdDev'][dfstat['Parameter']=='HR'].values[0]\n",
    "\n",
    "    rrnaf = (data['RRraw'].values - mRR)/sdRR\n",
    "    spo2naf = (data['SpO2raw'].values - mSpO2)/sdSpO2\n",
    "    hrnaf = (data['HRraw'].values - mHR)/sdHR\n",
    "    \n",
    "    X_TEST = np.zeros((1,TOTAL_LEN,3), dtype=np.float32)\n",
    "    X_TEST[0,:,0] = rrnaf\n",
    "    X_TEST[0,:,1] = spo2naf\n",
    "    X_TEST[0,:,2] = hrnaf\n",
    "    predictions = model.predict(X_TEST)\n",
    "    return predictions[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read p file corresponding to serial id as this will contain label of series\n",
    "# Read records using wfdb\n",
    "# Match lengths\n",
    "serial_id = 141\n",
    "refProbDf = pd.read_csv('SAXProb.csv')\n",
    "annofile = r'RDSegAnno.csv'\n",
    "model = getCNNModeltoInterpret('SegCNN.h5')\n",
    "LSTMmodel = getLSTMModeltoInterpret(fname)\n",
    "\n",
    "dfOuranno = pd.read_csv(annofile, encoding='iso-8859-1')  \n",
    "record_name = dfOuranno.loc[serial_id,'RecordNum'] \n",
    "flname = './FinalRecordsSeg/'+str(record_name)+'n.hea'\n",
    "recname = './FinalRecordsSeg/'+str(record_name)+'n'       \n",
    "[samples,R,S,H,firstline] = getIndexOfRRSpO2HR(flname)\n",
    "rec =  wfdb.io.rdrecord(str(recname))\n",
    "xrrFull = rec.p_signal[:,R]\n",
    "xspo2Full = rec.p_signal[:,S]\n",
    "xhrFull = rec.p_signal[:,H]\n",
    "TOTAL_LEN_FULL = len(xrrFull)\n",
    "print(TOTAL_LEN_FULL)\n",
    "tFull = np.arange(0,TOTAL_LEN_FULL,1)\n",
    "tnewFull = tFull/60.0\n",
    "myfn = str(serial_id)\n",
    "myfn = myfn.zfill(3)\n",
    "myfname = r'./SeriesSegData/p'+myfn+'.csv'\n",
    "SegAnnoDf = pd.read_csv(myfname, encoding='iso-8859-1')\n",
    "LabelsFull = SegAnnoDf['Label'].values\n",
    "fstat = './'+'parStat'+'.csv'\n",
    "StatDf = pd.read_csv(fstat, encoding='iso-8859-1')\n",
    "RRMean = StatDf[StatDf['Parameter']=='RR']['Mean'].values[0]\n",
    "RRStdDev = StatDf[StatDf['Parameter']=='RR']['StdDev'].values[0]\n",
    "SpO2Mean = StatDf[StatDf['Parameter']=='SpO2']['Mean'].values[0]\n",
    "SpO2StdDev = StatDf[StatDf['Parameter']=='SpO2']['StdDev'].values[0]\n",
    "HRMean = StatDf[StatDf['Parameter']=='HR']['Mean'].values[0]\n",
    "HRStdDev = StatDf[StatDf['Parameter']=='HR']['StdDev'].values[0]\n",
    "\n",
    "OUTLIERSD = 2.5\n",
    "LOWESSWINDOW = 3.0\n",
    "#fig = plt.figure(figsize=(10.5,8))\n",
    "STEP = 60\n",
    "j = 0\n",
    "for i in range(0,TOTAL_LEN_FULL,STEP):\n",
    "    fig = plt.figure(figsize=(10.5,8))\n",
    "    plt.clf()\n",
    "    ax = plt.axes(xlim=(-5,max(tnewFull)+5), ylim=(-30,135))\n",
    "    \n",
    "    xrr = xrrFull[0:i+STEP]\n",
    "    xspo2 = xspo2Full[0:i+STEP]\n",
    "    xhr = xhrFull[0:i+STEP]\n",
    "    t = tFull[0:i+STEP]\n",
    "    tnew = tnewFull[0:i+STEP]\n",
    "    Labels = LabelsFull[0:i+STEP]\n",
    "    TOTAL_LEN = len(xrr)\n",
    "\n",
    "    \n",
    "    \n",
    "    [rrnaf,t] = fillNAzero(xrr,t)\n",
    "    [spo2naf,t] = fillNAzero(xspo2,t)\n",
    "    [hrnaf,t] = fillNAzero(xhr,t)\n",
    "    \n",
    "    [xrrnew,t] = outlierRejector(xrr,t,OUTLIERSD)\n",
    "    [xspo2new,t] = outlierRejector(xspo2,t,OUTLIERSD)\n",
    "    [xhrnew,t] = outlierRejector(xhr,t,OUTLIERSD)\n",
    "\n",
    "    zrrnew = applyLowess(xrrnew,t,LOWESSWINDOW*60)\n",
    "    zspo2new = applyLowess(xspo2new,t,LOWESSWINDOW*60)\n",
    "    zhrnew = applyLowess(xhrnew,t,LOWESSWINDOW*60)\n",
    "    \n",
    "    rrnafNorm = (rrnaf - RRMean)/RRStdDev\n",
    "    spo2nafNorm = (spo2naf - SpO2Mean)/SpO2StdDev\n",
    "    hrnafNorm = (hrnaf - HRMean)/HRStdDev\n",
    "\n",
    "    X_TEST = np.zeros((1,TOTAL_LEN,3), dtype=np.float32)\n",
    "    X_TEST[0,:,0] = rrnafNorm\n",
    "    X_TEST[0,:,1] = spo2nafNorm\n",
    "    X_TEST[0,:,2] = hrnafNorm\n",
    "    \n",
    "    plt.scatter(tnew,xrr,c='hotpink',marker='.',alpha='0.1')\n",
    "    plt.scatter(tnew,xhr,c='magenta',marker='.',alpha='0.1')\n",
    "    plt.scatter(tnew,xspo2,c='cornflowerblue',marker='.',alpha='0.05')\n",
    "    \n",
    "    plt.plot(zrrnew[:,0]/60.0,(zrrnew[:,1]),'--r',label='RR',linewidth=2)\n",
    "    plt.plot(zhrnew[:,0]/60.0,(zhrnew[:,1]),'--m',label='HR',linewidth=2)\n",
    "    plt.plot(zspo2new[:,0]/60.0,(zspo2new[:,1]),'--b',label='SpO2',linewidth=2)\n",
    "    \n",
    "    # Every time we can model.predict size of X_TEST is different\n",
    "    predictions = model.predict(X_TEST)\n",
    "    movingAvgPredictions = movingAvg(predictions[0,:,0],120)\n",
    "    \n",
    "    predictionsLSTM = \n",
    "    \n",
    "    \n",
    "    SI = round(movingAvgPredictions[-1]*100)\n",
    "    SIstr = str(SI)+'%'\n",
    "    SAXprob = getSAXfromNormSeries(refProbDf,rrnafNorm,spo2nafNorm,hrnafNorm)\n",
    "    avgSAXprob = movingAvg(SAXprob,120)\n",
    "    T = round(tnew[-1])\n",
    "    Tstr = str(T)+' hrs'\n",
    "    \n",
    "    plt.plot(tnew,20*Labels-25.0,label='Clinical',linewidth=2)\n",
    "    # Plot CNN results\n",
    "    plt.plot(tnew,20*movingAvgPredictions-25.0,label='SI CNN',linewidth=2)\n",
    "    # Plot SAX results\n",
    "    #plt.plot(tnew,20*avgSAXprob-25.0,label='SAX',linewidth=2)\n",
    "    plt.legend(loc=2)\n",
    "        \n",
    "    plt.text(0,51,Tstr, fontsize=15)\n",
    "    plt.text(0,31,SIstr, fontsize=15)\n",
    "    filename='./ForGIF/step'+str(j).zfill(3)+'.png'\n",
    "    plt.savefig(filename, dpi=96)\n",
    "    j = j+1\n",
    "    plt.gca()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
